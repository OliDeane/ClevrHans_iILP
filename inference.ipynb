{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyswip import Prolog\n",
    "from inference import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pre-process text file\n",
    "* remove the \\n\n",
    "* remove the preceeding white space\n",
    "* combine current string with the next string if i+1 does not begin with true_class\n",
    "'''\n",
    "\n",
    "# Combine lines and clean strings\n",
    "def clean_theory(theory):\n",
    "    clean_theory = []\n",
    "    for i in range(0,len(theory)-1):\n",
    "        if ':-' not in theory[i+1]:\n",
    "                rule = theory[i].strip().replace('\\n', '') + ' ' + theory[i+1].strip().replace('\\n', '')\n",
    "                clean_theory.append(rule)\n",
    "    \n",
    "    return clean_theory\n",
    "\n",
    "def merge_lines(clean_theory):\n",
    "    # Tidy up to ensure all rules begin with head :- body\n",
    "    full_theory = []\n",
    "    if len(clean_theory) > 1:\n",
    "        for i in range(0,len(clean_theory)-1):\n",
    "            if ':-' not in clean_theory[i+1]:\n",
    "                    rule = clean_theory[i] + ' ' + clean_theory[i+1]\n",
    "                    full_theory.append(rule)\n",
    "            elif ':-' in clean_theory[i]:\n",
    "                full_theory.append(clean_theory[i])\n",
    "\n",
    "    else:\n",
    "        full_theory = clean_theory\n",
    "\n",
    "    return full_theory\n",
    "\n",
    "def add_variable(full_theory):\n",
    "    new_theory = []\n",
    "    for rule in full_theory:\n",
    "        head = 'true_class(A,EX) :-'\n",
    "        body = rule.rpartition(':-')[2][:-1]\n",
    "\n",
    "        new_body = body + ', Ex = ' + f'({body}).'\n",
    "        new_clause = head + new_body\n",
    "\n",
    "        new_theory.append(new_clause)\n",
    "    \n",
    "    return new_theory\n",
    "    \n",
    "def save_ruleset_to_prolog(dataset, filename, full_theory):\n",
    "    file = open(filename, 'w')\n",
    "    file.write(f':-consult(\"aleph_input/{dataset}_aleph.bk\").\\n')\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    for rule in full_theory:\n",
    "        head = 'true_class(A,Ex) :-'\n",
    "        body = rule.rpartition(':-')[2][:-1]\n",
    "\n",
    "        file.write(head + \"\\n\")\n",
    "        file.write(\"    \" + body + \",\\n\")\n",
    "        file.write(\"    Ex = \" + f\"[{body.strip()}].\\n\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "    file.close()        \n",
    "\n",
    "def translate_theory(dataset, filename = 'working_theory.pl'):\n",
    "\n",
    "    with open(f'{dataset}_theory.txt') as f:\n",
    "        theory = f.readlines()\n",
    "    \n",
    "    theory = clean_theory(theory)\n",
    "    theory = merge_lines(theory)\n",
    "    save_ruleset_to_prolog(dataset, filename, theory)\n",
    "\n",
    "def single_instance_inference(dataset, example_number, prolog):\n",
    "    translate_theory(dataset = dataset)\n",
    "    prolog.consult(\"working_theory.pl\")\n",
    "    result = list(prolog.query(f\"true_class(example_{example_number}, Explanation)\"))\n",
    "\n",
    "    # Extract prediction and explanation\n",
    "    if len(result) == 0:\n",
    "        pred = 0\n",
    "        explanation = None\n",
    "    elif len(result) == 1:\n",
    "        pred = 1\n",
    "        explanation = result[0]['Explanation']\n",
    "    else: # need to fix this - why is some len 1 and others more?\n",
    "        pred = 1\n",
    "        explanation = result[0]['Explanation']\n",
    "\n",
    "    return (pred, explanation)\n",
    "\n",
    "def add_constraint(dataset):\n",
    "    output_directory = 'aleph_input'\n",
    "    bk_file = open(output_directory + '/' + dataset + '_aleph.bk', 'a')\n",
    "\n",
    "    bk_file.write(\":-consult('constraints.pl').\\n\")\n",
    "    bk_file.write(\"bodyList(Body, FinalList) :-\\n \\\n",
    "        clause2list(Body,[],Output, Clause), list_to_term(Clause, Term), insertAtEnd(Term,Output,FinalList).\\n\")\n",
    "    bk_file.write(\"false :- \\n\\\n",
    "        hypothesis(_,Body,_), bodyList(Body, List), !, member(has_color(_,_), List).\")\n",
    "    \n",
    "\n",
    "\n",
    "    bk_file.close()\n",
    "\n",
    "def ilp_induce(dataset, prolog):\n",
    "    # generate initial ILP thoery and save to a file\n",
    "    prolog.consult('aleph6.pl')\n",
    "    list(prolog.query(f\"read_all('aleph_input/{dataset}_aleph').\"))\n",
    "    list(prolog.query(\"induce.\"))\n",
    "    list(prolog.query(f\"write_rules('{dataset}_theory.txt').\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ilp_induce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7z/lrptyln56gbbf5cj00pqyjf40000gn/T/ipykernel_1999/3429824891.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprolog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0milp_induce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprolog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mresult1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_instance_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprolog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprolog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ilp_induce' is not defined"
     ]
    }
   ],
   "source": [
    "# Initial theory with prediction\n",
    "\n",
    "dataset = 'hans'\n",
    "prolog = Prolog()\n",
    "\n",
    "ilp_induce(dataset, prolog)\n",
    "result1 = single_instance_inference(dataset=dataset, example_number=3, prolog=prolog)\n",
    "\n",
    "# # Add constraint and re-train ILP program\n",
    "add_constraint(dataset)\n",
    "ilp_induce(dataset, prolog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, ['contains(oid_91, example_3)', 'has_shape(oid_91, cylinder)', 'contains(oid_1, example_3)', 'has_shape(oid_1, cube)', 'contains(oid_91, example_3)', 'has_shape(oid_91, cylinder)', 'contains(oid_1, example_3)', 'has_shape(oid_1, cube)', 'has_color(oid_1, gray)']) \n",
      "\n",
      " (1, ['contains(oid_91, example_3)', 'has_shape(oid_91, cylinder)', 'has_size(oid_91, large)', 'contains(oid_14, example_3)', 'contains(oid_91, example_3)', 'has_shape(oid_91, cylinder)', 'has_size(oid_91, large)', 'contains(oid_14, example_3)', 'has_shape(oid_14, cube)'])\n"
     ]
    }
   ],
   "source": [
    "# Show results with/out new added constraint\n",
    "result2 = single_instance_inference(dataset=dataset, example_number=3, prolog=prolog)\n",
    "print(result1, '\\n\\n',result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 ('ilp_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a438c5a9d814fdcf4c71bfa51aee82b7b3f77bdca39ab43f22c1c3326f23fe8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
