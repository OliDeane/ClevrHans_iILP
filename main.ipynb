{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "from samples.clevr import clevr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained MRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"sample_images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(clevr.ClevrConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.80\n",
    "    DETECTION_NMS_THRESHOLD = 0.20\n",
    "\n",
    "config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "# CLEVR_MODEL_PATH = '/Users/fl20994/Documents/IAI_CDT/Research_Project/relationalReasoning/INeSyXL/CLEVR-Hans3/ClevrHans_ILP/trained_model/mask_rcnn_clevr_0030_allclasses.h5'\n",
    "CLEVR_MODEL_PATH = './trained_model/mask_rcnn_clevr_0030_allclasses.h5'\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(CLEVR_MODEL_PATH, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_categories = {'cube': 1,\n",
    "                            'sphere': 2,\n",
    "                            'cylinder': 3}\n",
    "material_categories = {'rubber': 1,\n",
    "                               'metal': 2}\n",
    "color_categories = {'gray': 1,\n",
    "                            'blue': 2,\n",
    "                            'brown': 3,\n",
    "                            'yellow': 4,\n",
    "                            'red': 5,\n",
    "                            'green': 6,\n",
    "                            'purple': 7,\n",
    "                            'cyan': 8}\n",
    "size_categories = {'small': 1,\n",
    "                           'large': 2}\n",
    "class_names = ['BG']\n",
    "for shape in shape_categories:\n",
    "    for mat in material_categories:\n",
    "        for col in color_categories:\n",
    "            for size in size_categories:\n",
    "                class_name = shape + \" \" + mat + \" \" + col + \" \" + size\n",
    "                class_names.append(class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference on random img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = next(os.walk(IMAGE_DIR))[2]\n",
    "image = skimage.io.imread(os.path.join(IMAGE_DIR, file_names[1]))\n",
    "image = image[:,:,:3]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            class_names, r['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to Aleph Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory of images to run detection on\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"temp_images/\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on all images in sample images folder\n",
    "# oblist contains list of objects in each of the images\n",
    "\n",
    "def inference(IMAGE_DIR, model):\n",
    "\n",
    "    file_names = sorted(next(os.walk(IMAGE_DIR))[2])\n",
    "\n",
    "    if '.DS_Store' in file_names:\n",
    "        file_names.remove(\".DS_Store\")\n",
    "\n",
    "    oblist = []\n",
    "    ilp_classes = []\n",
    "    \n",
    "    print('Detecting objects...')\n",
    "\n",
    "    for filename in tqdm(file_names):\n",
    "        image = skimage.io.imread(os.path.join(IMAGE_DIR, filename))\n",
    "        image = image[:,:,:3]\n",
    "        results = model.detect([image], verbose=0)\n",
    "        r = results[0]\n",
    "        oblist.append([class_names[r['class_ids'][i]] for i in range(len(r['class_ids']))])\n",
    "        ilp_classes.append(f'c{filename[19]}')\n",
    "    \n",
    "    return oblist, ilp_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_files():\n",
    "\n",
    "    output_filename = 'hans_aleph'\n",
    "    output_directory = os.getcwd()\n",
    "\n",
    "    os.makedirs(ROOT_DIR, exist_ok=True)\n",
    "\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    b_file = open(output_directory + '/' + output_filename + '.b', 'w')\n",
    "    f_file = open(output_directory + '/' + output_filename + '.f', 'w')\n",
    "    n_file = open(output_directory + '/' + output_filename + '.n', 'w')\n",
    "    bk_file = open(output_directory + '/' + output_filename + '.bk', 'w')\n",
    "\n",
    "    return b_file, f_file, n_file, bk_file\n",
    "\n",
    "def write_basic_preds(bk_file, color_categories, material_categories, size_categories, shape_categories):\n",
    "\n",
    "    attribute_dict = {'color': list(color_categories.keys()), 'material': list(material_categories.keys()),\n",
    "                        'size': list(size_categories.keys()), 'shape': list(shape_categories.keys())}\n",
    "\n",
    "    for attribute in list(attribute_dict.keys()):\n",
    "        bk_file.write(f\":- discontiguous has_{attribute}/2.\\n\")\n",
    "\n",
    "    bk_file.write(\"\\n\")\n",
    "\n",
    "    for category in list(attribute_dict.keys()):\n",
    "        for attribute in attribute_dict[category]:\n",
    "            bk_file.write(f\"{category}({attribute}).\\n\")\n",
    "\n",
    "    bk_file.write(\"\\n\")\n",
    "\n",
    "    return attribute_dict\n",
    "\n",
    "def write_object_preds(bk_file, attribute_dict):\n",
    "\n",
    "    class_names[r['class_ids'][0]]\n",
    "\n",
    "    full_oblist = []\n",
    "    for shape in attribute_dict['shape']:\n",
    "        for material in attribute_dict['material']:\n",
    "            for color in attribute_dict['color']:\n",
    "                for size in attribute_dict['size']:\n",
    "                    full_oblist.append([shape, material, color, size])\n",
    "\n",
    "    object_count = 0 \n",
    "    for object in full_oblist:\n",
    "        object_id = f'oid_{object_count}'\n",
    "        shape, material, color, size = object\n",
    "        bk_file.write(f\"has_shape({object_id}, {shape}).\\n\")\n",
    "        bk_file.write(f\"has_material({object_id}, {material}).\\n\")\n",
    "        bk_file.write(f\"has_color({object_id}, {color}).\\n\")\n",
    "        bk_file.write(f\"has_size({object_id}, {size}).\\n\")\n",
    "        bk_file.write(f\"\\n\")\n",
    "        object_count += 1\n",
    "    \n",
    "    return full_oblist\n",
    "\n",
    "def write_img_facts(bk_file, full_oblist, oblist):\n",
    "\n",
    "    example_count = 0\n",
    "    for img_objects in oblist:\n",
    "        bk_file.write(\"\\n\")\n",
    "        example_id = f\"example_{example_count}\"\n",
    "        example_count += 1\n",
    "\n",
    "        for object in img_objects:\n",
    "            shape, material, color, size = object.split()\n",
    "\n",
    "            # find the index id of the object recognised\n",
    "            object_idx = full_oblist.index([shape, material, color, size])\n",
    "            object_id = f'oid_{object_idx}'\n",
    "            bk_file.write(f\"contains({object_id}, {example_id}).\\n\")\n",
    "\n",
    "def close_files(b_file, f_file, n_file, bk_file):\n",
    "    b_file.close()\n",
    "    bk_file.close()\n",
    "    f_file.close()\n",
    "    n_file.close()\n",
    "\n",
    "def write_img_object_preds(oblist):\n",
    "    '''Ignore for now.\n",
    "    This write predicates for only the object that appear in the training set. NOT for all possible objects'''\n",
    "    example_count = 0\n",
    "    object_count = 0\n",
    "    for img_objects in oblist:\n",
    "        bk_file.write(\"\\n\")\n",
    "        example_id = f\"example_{example_count}\"\n",
    "        example_count += 1\n",
    "\n",
    "        for object in img_objects:\n",
    "            object_id = f'oid_{object_count}'\n",
    "            shape, material, color, size = object.split()\n",
    "            bk_file.write(f\"has_shape({object_id}, {shape}).\\n\")\n",
    "            bk_file.write(f\"has_material({object_id}, {material}).\\n\")\n",
    "            bk_file.write(f\"has_color({object_id}, {color}).\\n\")\n",
    "            bk_file.write(f\"has_size({object_id}, {size}).\\n\")\n",
    "            object_count += 1\n",
    "        \n",
    "        bk_file.write(f\"contains({object_id}, {example_id}).\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ground_truths(ilp_classes, f_file, n_file):\n",
    "    for id in range(0,len(ilp_classes)):\n",
    "        if ilp_classes[id] == 'c0':\n",
    "            f_file.write(f\"true_class(example_{id}).\\n\")\n",
    "        else:\n",
    "            n_file.write(f\"true_class(example_{id}).\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_aleph_settings(b_file, features = ['shape','material','color','size'], \\\n",
    "    id_column = \"oid\", output_filename = \"hans_aleph\"):\n",
    "\n",
    "    # write settings for Aleph\n",
    "    b_file.write(\":- modeh(1, true_class(+example)).\\n\")\n",
    "    b_file.write(\"\\n\")\n",
    "\n",
    "    b_file.write(f\":- modeb(*, contains(-{id_column}, +example)).\\n\")\n",
    "\n",
    "    # modes\n",
    "    for feature in features:\n",
    "        b_file.write(f\":- modeb(*, has_{feature}(+{id_column}, #{feature})).\\n\")\n",
    "\n",
    "    b_file.write(\"\\n\")\n",
    "\n",
    "    # determinations\n",
    "    b_file.write(\":- determination(true_class/1, contains/2).\\n\")\n",
    "\n",
    "    for feature in features:\n",
    "        b_file.write(f\":- determination(true_class/1, has_{feature}/2).\\n\")\n",
    "\n",
    "    b_file.write(\"\\n\")\n",
    "    \n",
    "    b_file.write(\":- set(i,4).\\n\")\n",
    "    b_file.write(\":- set(verbosity,0).\\n\")\n",
    "    b_file.write(\":- set(minpos,3).\\n\")\n",
    "    b_file.write(\":- set(noise,10).\\n\")\n",
    "    b_file.write(\":- set(clauselength, 20).\\n\")\n",
    "    b_file.write(f\":- consult('{output_filename + '.bk'}').\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149/149 [08:51<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "oblist, ilp_classes = inference(IMAGE_DIR, model)\n",
    "b_file, f_file, n_file, bk_file = open_files()\n",
    "write_aleph_settings(b_file)\n",
    "attribute_dict = write_basic_preds(bk_file, color_categories, material_categories, size_categories, shape_categories)\n",
    "full_oblist = write_object_preds(bk_file, attribute_dict)\n",
    "write_img_facts(bk_file, full_oblist, oblist)\n",
    "write_ground_truths(ilp_classes, f_file, n_file)\n",
    "close_files(b_file, f_file, n_file, bk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('introtoai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de2a7fbcd31f835c65557fe10486cbf042d1baa090021dd39bf8d88d2954fef8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
